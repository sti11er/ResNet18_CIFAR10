{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import time\n",
        "import torch.nn.init as init\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from copy import deepcopy\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "bPbSv6sIUhS3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MixApp(nn.Module):\n",
        "    def __init__(self, alpha=1.0, prob=0.5):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.prob = prob\n",
        "\n",
        "    def forward(self, img):\n",
        "        if torch.rand(1) < self.prob:\n",
        "            # Генерируем lambda из Beta-распределения\n",
        "            lam = torch.distributions.beta.Beta(self.alpha, self.alpha).sample()\n",
        "\n",
        "            # Горизонтальное отражение (работает с тензорами [C,H,W])\n",
        "            augmented_img = torch.flip(img, dims=[2])  # dims=[2] - горизонтальный flip\n",
        "\n",
        "            # Линейная интерполяция между изображениями\n",
        "            mixed_img = lam * img + (1 - lam) * augmented_img\n",
        "\n",
        "            return mixed_img\n",
        "        return img"
      ],
      "metadata": {
        "id": "iaeo6gJ9UyNf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_transform = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_train_1 = transforms.Compose([\n",
        "   transforms.RandomCrop(32, padding=4),\n",
        "   transforms.RandomHorizontalFlip(),\n",
        "   transforms.ToTensor(),\n",
        "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_train_2 = transforms.Compose([\n",
        "   transforms.ToTensor(),\n",
        "   MixApp(alpha=0.4),\n",
        "   transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "metadata": {
        "id": "iW_fhQz2Urmj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_train = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=base_transform\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izmrOeujUvaI",
        "outputId": "92012677-443e-467b-ea2d-e5a954b103d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 47.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train_1 = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=False,\n",
        "    transform=transform_train_1\n",
        ")\n",
        "\n",
        "half_size = len(augmented_train_1) // 2\n",
        "augmented_train_1, _ = random_split(augmented_train_1, [half_size, len(augmented_train_1) - half_size])"
      ],
      "metadata": {
        "id": "Y68z2pf7U9a8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train_2 = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=False,\n",
        "    transform=transform_train_2\n",
        ")\n",
        "\n",
        "half_size = len(augmented_train_2) // 2\n",
        "augmented_train_2, _ = random_split(augmented_train_2, [half_size, len(augmented_train_2) - half_size])"
      ],
      "metadata": {
        "id": "2p25qKfIVBD9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_train = ConcatDataset([augmented_train_1, augmented_train_2])"
      ],
      "metadata": {
        "id": "YlcQTLcoVCIn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=base_transform\n",
        ")"
      ],
      "metadata": {
        "id": "wg9W9lJ7VDWA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ConcatDataset([original_train, augmented_train])"
      ],
      "metadata": {
        "id": "jkJS5c-FVEoo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_epochs = 15"
      ],
      "metadata": {
        "id": "X_e4FAXmVHI3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "mybYwLIBVJX3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(torch.nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                                     padding=1, bias=False)\n",
        "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
        "                                     padding=1, bias=False)\n",
        "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "QB3mpR01VMvz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18(torch.nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        # [b, 3, 64, 64]\n",
        "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        # [b, 64, 32, 32]\n",
        "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
        "        # [b, 64, 32, 32]\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # [b, 64, 32, 32]\n",
        "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # [b, 64, 16, 16]\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            BasicBlock(64, 64),\n",
        "            BasicBlock(64, 64),\n",
        "        )\n",
        "        # [b, 64, 16, 16]\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            BasicBlock(64, 128, stride=2, downsample=torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(64, 128, kernel_size=1, stride=2),\n",
        "                torch.nn.BatchNorm2d(128),\n",
        "            )),\n",
        "            BasicBlock(128, 128),\n",
        "        )\n",
        "        # [b, 128, 8, 8]\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            BasicBlock(128, 256, stride=2, downsample=torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(128, 256, kernel_size=1, stride=2),\n",
        "                torch.nn.BatchNorm2d(256),\n",
        "            )),\n",
        "            BasicBlock(256, 256),\n",
        "        )\n",
        "        # [b, 256, 4, 4]\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            BasicBlock(256, 512, stride=2, downsample=torch.nn.Sequential(\n",
        "                torch.nn.Conv2d(256, 512, kernel_size=1, stride=2),\n",
        "                torch.nn.BatchNorm2d(512),\n",
        "            )),\n",
        "            BasicBlock(512, 512),\n",
        "        )\n",
        "        # [b, 512, 2, 2]\n",
        "\n",
        "        self.avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))\n",
        "        # [b, 512, 1, 1]\n",
        "        self.fc = torch.nn.Linear(512, num_classes)\n",
        "        # [b, 10]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZPTms3O2VSHW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "model = ResNet18().to(device)"
      ],
      "metadata": {
        "id": "PLyOvEAvVVPs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(X_batch, y_batch):\n",
        "    logits = model(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch)"
      ],
      "metadata": {
        "id": "ZiD8tgPSVbJp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_loss_ = []\n",
        "val_accuracy_ = []"
      ],
      "metadata": {
        "id": "dBRQThjTVcTw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss = []\n",
        "    val_accuracy = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    for (X_batch, y_batch) in trainloader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for (X_batch, y_batch) in valloader:\n",
        "          X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "          logits = model(torch.as_tensor(X_batch, dtype=torch.float32))\n",
        "          y_pred = logits.argmax(dim=1)\n",
        "\n",
        "          accuracy = (y_batch == y_pred).float().mean()\n",
        "          val_accuracy.append(accuracy)\n",
        "\n",
        "    train_loss_tensor = torch.tensor(train_loss)\n",
        "    training_loss = train_loss_tensor.mean().item()\n",
        "\n",
        "    val_accuracy_tensor = torch.tensor(val_accuracy)\n",
        "    validation_acc = val_accuracy_tensor.mean().item() * 100\n",
        "\n",
        "    train_loss_.append(training_loss)\n",
        "    val_accuracy_.append(validation_acc)\n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "          training_loss))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        validation_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "vmk-yFELVdbV",
        "outputId": "26f7d137-9f37-4d9c-d4ee-d389b45f032d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-25-3548120071.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxS7kDYwVmBc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}